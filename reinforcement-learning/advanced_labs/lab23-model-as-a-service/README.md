# Lab 23: AI即服务 - 构建模型路由与合成系统

## 🎯 学习目标

本实验将引导您探索一个更宏大、更具未来感的AI系统构想——**模型即服务（Model-as-a-Service, MaaS）**。您将学习如何从构建单一的、巨大的"万能"模型，转向构建一个由大量**中小型专用模型**组成的、可以根据任务需求**自适应组合**的生态系统。这就像从"巨型应用"走向"微服务架构"。

## 核心任务

1.  **理论学习：MaaS的核心思想**
    *   **"万能"模型的瓶颈**: 理解为什么训练和部署一个能处理所有任务的巨型模型，在成本、效率和可维护性上都面临巨大挑战。
    *   **MaaS架构**:
        1.  **模型路由器 (Model Router)**: 一个高层次的、轻量级的路由模型。它的唯一职责是**分析用户请求**，然后判断哪个或哪些下游的"专家模型"最适合处理这个请求，并将任务**分发**下去。这本身是一个分类或简单的LLM推理任务。
        2.  **专家模型池 (Pool of Expert Models)**: 一个包含各种**专用模型**的库。这些模型经过专门训练，在各自的领域（如翻译、代码生成、情感分析、数学推理）表现出色。它们是系统的"工作单元"。
        3.  **结果合成器 (Result Synthesizer)**: 在接收到一个或多个专家模型的返回结果后，可能需要一个"合成模型"（通常是通用的LLM）将这些碎片化的信息整合成一个统一、连贯的最终答案，呈现给用户。

2.  **实践操作：构建一个简单的MaaS系统**
    *   **准备专家模型池**:
        - 为了简化，您不需要重新训练。可以选择2-3个现有的、小型的、有不同专长的开源模型。例如：
            - **专家A (代码专家)**: `TinyLlama/TinyLlama-1.1B-Chat-v1.0`
            - **专家B (翻译专家)**: `Helsinki-NLP/opus-mt-en-zh`
            - **专家C (情感分析专家)**: `distilbert-base-uncased-finetuned-sst-2-english`
    *   **构建模型路由器**:
        - 训练一个简单的分类器（例如，使用`scikit-learn`训练一个`LogisticRegression`），它可以根据请求中的关键词（如"translate", "code", "feeling"）来判断应该调用哪个专家。
        - （进阶）使用一个轻量级的LLM（如`GPT-2`）作为路由器，通过提示工程让它输出应该调用的专家名称。
    *   **实现API网关**:
        - 使用`FastAPI`创建一个简单的Web服务。
        - 设计一个API端点 `/dispatch`，它接收用户请求。
        - 在端点内部，依次调用**路由器**进行任务分配，然后调用对应的**专家模型**执行任务，最后将专家的结果直接返回（本实验可省略合成器）。

## 📝 预期成果

- 深刻理解"模型即服务"（MaaS）和"AI微服务"的架构思想。
- 一个可以运行的、基于FastAPI的MaaS原型系统，它能根据用户请求动态地调用不同的专家模型。
- 掌握了将多个独立的AI模型整合成一个协同工作系统的基本方法。
- 对未来AI系统的形态——从单一巨型模型到分布式、自适应的模型网络——有了更前瞻的认识。 