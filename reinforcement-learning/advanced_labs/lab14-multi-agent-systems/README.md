# Lab 14: 多智能体博弈与协作 (Multi-Agent RL)

## 🎯 学习目标

本实验将引导您从之前`1v1`的攻防博弈框架，进入更复杂、也更贴近真实世界动态的**多智能体（Multi-Agent）**系统。您将学习如何设计和分析多智能体环境中的合作与竞争，并探索可能从中涌现出的复杂社会行为。

## 核心任务

1.  **引入多智能体RL (MARL) 框架**:
    - 学习并掌握一个主流的MARL研究框架，例如 `PettingZoo` 或 `MeltingPot`。
    - 理解MARL环境与单智能体环境的核心区别（如共享观测、联合动作空间、共享奖励等）。
    - 改造您现有的RL训练器，使其能够支持多智能体并行训练。

2.  **设计并实现"合作型"场景**:
    - 构建一个需要多个智能体协作才能完成任务的环境。
    - **示例场景**："多分析师情报系统"。
        - **环境**: 多个"分析师"智能体分别接收到部分、碎片化的信息。
        - **目标**: 它们必须通过有效的通信与协作，拼凑出完整的情报，共同识别并抵御一个"攻击者"智能体的渗透。
        - **挑战**: 如何设计奖励函数来鼓励有效的合作，而不是个体"抢功"？

3.  **设计并实现"混合型"博弈场景**:
    - 构建一个同时包含合作与竞争的复杂环境。
    - **示例场景**："三方安全博弈"。
        - **环境**: 包含三类角色：**防御者**(Defenders), **攻击者**(Attackers), **中立者**(Neutrals)。
        - **目标**: 
            - 防御者希望维护系统稳定（合作关系）。
            - 攻击者希望搞破坏（与防御者是竞争关系）。
            - 中立者只关心自身利益最大化，可能与防御者合作，也可能被攻击者利用。
        - **挑战**: 分析不同角色之间动态变化的联盟关系和策略选择。

4.  **分析与可视化"涌现行为"**:
    - "涌现行为"（Emergent Behavior）是指系统中个体简单的交互规则，在宏观层面产生了意料之外的复杂集体行为。
    - 学习如何设计指标来度量和分析智能体之间的社会行为，例如：
        - **合作度**: 智能体之间分享奖励或信息的频率。
        - **信任度**: 智能体接受其他智能体建议的概率。
        - **策略演化**: 可视化智能体策略随时间演化的过程，观察联盟的形成与瓦解。

## 📝 预期成果

- 一个基于 `PettingZoo` 或类似框架的、可运行的多智能体RL实验平台。
- 至少两个完整实现的多智能体场景（一个合作型，一个混合型）。
- 一份关于多智能体系统中"涌现行为"的深度分析报告，包含量化指标和可视化图表。
- 掌握分析和设计复杂社会-技术系统（Socio-Technical Systems）中智能体交互的基础能力。 