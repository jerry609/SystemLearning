# ğŸš€ å¿«é€ŸæŸ¥æ‰¾æŒ‡å—

å½“ä½ é‡åˆ°é—®é¢˜æ—¶ï¼Œä½¿ç”¨è¿™ä¸ªæŒ‡å—å¿«é€Ÿå®šä½ç›¸å…³çš„è§£å†³æ–¹æ¡ˆæ–‡æ¡£ã€‚

## ğŸ” æŒ‰é”™è¯¯ç±»å‹æŸ¥æ‰¾

### CUDAé”™è¯¯
```
RuntimeError: CUDA error: device-side assert triggered
AssertionError: input[0] != 0
```
**ğŸ“„ æŸ¥çœ‹**: `cuda-errors/multinomial-assertion-failure.md`

### è®­ç»ƒé—®é¢˜
```
æ¢¯åº¦èŒƒæ•°çªç„¶å˜å¾—å¾ˆå¤§ (>1000)
æ¨¡å‹å‚æ•°åŒ…å« NaN æˆ– inf
è®­ç»ƒç¬¬äºŒè½®å¼€å§‹å°±å¤±è´¥
```
**ğŸ“„ æŸ¥çœ‹**: `training-issues/grpo-gradient-explosion.md`

## ğŸ” æŒ‰ç®—æ³•æŸ¥æ‰¾

### GRPO (Group Relative Policy Optimization)
- **CUDAé”™è¯¯**: `cuda-errors/multinomial-assertion-failure.md`
- **æ¢¯åº¦çˆ†ç‚¸**: `training-issues/grpo-gradient-explosion.md`

### PPO (Proximal Policy Optimization)
- **æ•°å€¼ç¨³å®šæ€§**: `training-issues/grpo-gradient-explosion.md` (æŠ€æœ¯é€šç”¨)

## ğŸ” æŒ‰ç—‡çŠ¶æŸ¥æ‰¾

| ç—‡çŠ¶ | å¯èƒ½åŸå›  | æŸ¥çœ‹æ–‡æ¡£ |
|------|----------|----------|
| ğŸ”¥ è®­ç»ƒç¬¬ä¸€è½®æˆåŠŸï¼Œç¬¬äºŒè½®å´©æºƒ | æ¢¯åº¦çˆ†ç‚¸ + CUDAé”™è¯¯ | CUDA-001 + TRAIN-001 |
| ğŸ’¥ `torch.multinomial` æŠ¥é”™ | æ¦‚ç‡åˆ†å¸ƒå¼‚å¸¸ | CUDA-001 |
| ğŸ“ˆ æ¢¯åº¦èŒƒæ•° >10000 | æ¢¯åº¦çˆ†ç‚¸ | TRAIN-001 |
| ğŸ§® å‚æ•°åŒ…å« NaN/inf | æ•°å€¼æº¢å‡º | TRAIN-001 |
| ğŸ–¥ï¸ GPU çŠ¶æ€æŸå | CUDAæ–­è¨€å¤±è´¥ | CUDA-001 |
| ğŸ”„ éœ€è¦é‡å¯è¿›ç¨‹æ‰èƒ½ç»§ç»­ | CUDAä¸Šä¸‹æ–‡ç ´å | CUDA-001 |

## ğŸ” æŒ‰æŠ€æœ¯æ ˆæŸ¥æ‰¾

### PyTorch + CUDA
- **multinomialé‡‡æ ·**: `cuda-errors/multinomial-assertion-failure.md`
- **æ¢¯åº¦è®¡ç®—**: `training-issues/grpo-gradient-explosion.md`

### å¼ºåŒ–å­¦ä¹ 
- **ç­–ç•¥ä¼˜åŒ–**: `training-issues/grpo-gradient-explosion.md`
- **PPOå˜ç§**: `cuda-errors/multinomial-assertion-failure.md`

### æ•°å€¼è®¡ç®—
- **æ•°å€¼ç¨³å®šæ€§**: ä¸¤ä¸ªæ–‡æ¡£éƒ½æ¶‰åŠ
- **æ¢¯åº¦è£å‰ª**: `training-issues/grpo-gradient-explosion.md`

## ğŸ“‹ å¸¸ç”¨æ£€æŸ¥æ¸…å•

### é‡åˆ°è®­ç»ƒé—®é¢˜æ—¶
```bash
# 1. æ£€æŸ¥æ¢¯åº¦èŒƒæ•°
print(f"æ¢¯åº¦èŒƒæ•°: {grad_norm:.2f}")

# 2. æ£€æŸ¥å‚æ•°å¥åº·
nan_count = sum(torch.isnan(p).sum() for p in model.parameters())
inf_count = sum(torch.isinf(p).sum() for p in model.parameters())

# 3. æ£€æŸ¥æŸå¤±å€¼
print(f"æŸå¤±: {loss.item():.6f}")

# 4. æ£€æŸ¥logitsèŒƒå›´
print(f"logitsèŒƒå›´: [{logits.min():.2f}, {logits.max():.2f}]")
```

### é‡åˆ°CUDAé”™è¯¯æ—¶
```bash
# 1. æŸ¥çœ‹å®Œæ•´é”™è¯¯ä¿¡æ¯
CUDA_LAUNCH_BLOCKING=1 python your_script.py

# 2. æ£€æŸ¥CUDAçŠ¶æ€
torch.cuda.empty_cache()
torch.cuda.synchronize()

# 3. éªŒè¯è¾“å…¥æ•°æ®
print(f"è¾“å…¥å½¢çŠ¶: {input_tensor.shape}")
print(f"æ•°æ®ç±»å‹: {input_tensor.dtype}")
print(f"è®¾å¤‡: {input_tensor.device}")
```

## ğŸ› ï¸ é€šç”¨ä¿®å¤ç­–ç•¥

### æ•°å€¼ç¨³å®šæ€§
1. **é™ä½å­¦ä¹ ç‡** (1e-5 â†’ 5e-6)
2. **ä¸¥æ ¼æ¢¯åº¦è£å‰ª** (0.5 â†’ 0.3)
3. **é™åˆ¶ä¸­é—´å€¼èŒƒå›´** (clampæ“ä½œ)
4. **æ·»åŠ å¥åº·æ£€æŸ¥** (NaN/infç›‘æ§)

### CUDAç›¸å…³
1. **ä¿å®ˆç”Ÿæˆå‚æ•°** (temperature, top_p)
2. **é”™è¯¯æ¢å¤æœºåˆ¶** (å¼‚å¸¸è·³è¿‡)
3. **çŠ¶æ€é‡ç½®** (æ¸…ç†GPUç¼“å­˜)
4. **æ•°æ®éªŒè¯** (è¾“å…¥åˆæ³•æ€§æ£€æŸ¥)

## ğŸ”— æ‰©å±•é˜…è¯»

- **ä¸»ç´¢å¼•**: `README.md`
- **æ–‡æ¡£æ¨¡æ¿**: `template.md`
- **é¡¹ç›®æ–‡æ¡£**: `../README.md`

---

ğŸ’¡ **æç¤º**: 
- ä½¿ç”¨ `Ctrl+F` æœç´¢å…³é”®è¯
- å¤šæ•°é—®é¢˜éƒ½æœ‰æ˜ç¡®çš„è§£å†³æ­¥éª¤
- æŒ‰ç…§æ–‡æ¡£ä¸­çš„é…ç½®å‚æ•°å¯ä»¥å¿«é€Ÿä¿®å¤
- å¦‚æœé—®é¢˜ä»æœªè§£å†³ï¼Œå¯ä»¥å‚è€ƒç›¸å…³èµ„æºé“¾æ¥ 